[2025-05-07T19:40:21.691+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:40:21.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:40:21.694+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:40:21.694+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:40:25.629+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:40:25.620+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:40:25.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:40:25.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.966 seconds
[2025-05-07T19:40:56.266+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:40:56.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:40:56.269+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:40:56.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:41:00.120+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:41:00.111+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:41:00.123+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:41:00.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.878 seconds
[2025-05-07T19:41:30.785+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:41:30.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:41:30.788+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:41:30.788+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:41:34.701+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:41:34.691+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:41:34.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:41:34.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.943 seconds
[2025-05-07T19:42:05.298+0000] {processor.py:161} INFO - Started process (PID=876) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:05.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:42:05.301+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:05.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:09.425+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:09.400+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:42:09.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:09.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 4.161 seconds
[2025-05-07T19:42:39.903+0000] {processor.py:161} INFO - Started process (PID=1046) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:39.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:42:39.906+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:39.906+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:43.623+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:43.614+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:42:43.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:43.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.746 seconds
[2025-05-07T19:42:47.209+0000] {processor.py:161} INFO - Started process (PID=1211) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:47.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:42:47.212+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:47.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:51.050+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:42:51.042+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:42:51.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:42:51.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.866 seconds
[2025-05-07T19:43:21.517+0000] {processor.py:161} INFO - Started process (PID=1381) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:21.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:43:21.520+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:43:21.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:25.378+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:43:25.369+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:43:25.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:25.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.891 seconds
[2025-05-07T19:43:55.897+0000] {processor.py:161} INFO - Started process (PID=1552) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:55.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:43:55.900+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:43:55.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:59.554+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:43:59.545+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:43:59.558+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:43:59.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.682 seconds
[2025-05-07T19:44:30.054+0000] {processor.py:161} INFO - Started process (PID=1722) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:44:30.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:44:30.057+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:44:30.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:44:33.549+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:44:33.541+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:44:33.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:44:33.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.522 seconds
[2025-05-07T19:45:04.569+0000] {processor.py:161} INFO - Started process (PID=1898) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:04.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:45:04.571+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:45:04.571+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:08.399+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:45:08.389+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:45:08.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:08.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.856 seconds
[2025-05-07T19:45:38.683+0000] {processor.py:161} INFO - Started process (PID=2069) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:38.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:45:38.686+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:45:38.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:42.404+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:45:42.396+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:45:42.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:45:42.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.745 seconds
[2025-05-07T19:46:13.273+0000] {processor.py:161} INFO - Started process (PID=2239) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:13.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:46:13.276+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:46:13.275+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:16.946+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:46:16.937+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:46:16.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:16.968+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.697 seconds
[2025-05-07T19:46:47.035+0000] {processor.py:161} INFO - Started process (PID=2411) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:47.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:46:47.038+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:46:47.037+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:50.717+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:46:50.709+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:46:50.721+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:46:50.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.708 seconds
[2025-05-07T19:47:21.291+0000] {processor.py:161} INFO - Started process (PID=2581) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:21.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:47:21.293+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:47:21.293+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:25.100+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:47:25.092+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:47:25.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:25.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.835 seconds
[2025-05-07T19:47:55.590+0000] {processor.py:161} INFO - Started process (PID=2753) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:55.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:47:55.593+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:47:55.593+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:59.281+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:47:59.273+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:47:59.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:47:59.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.717 seconds
[2025-05-07T19:48:29.875+0000] {processor.py:161} INFO - Started process (PID=2924) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:48:29.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:48:29.878+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:48:29.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:48:33.466+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:48:33.458+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:48:33.469+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:48:33.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.615 seconds
[2025-05-07T19:49:03.976+0000] {processor.py:161} INFO - Started process (PID=3099) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:03.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:49:03.979+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:49:03.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:07.666+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:49:07.657+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:49:07.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:07.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.716 seconds
[2025-05-07T19:49:38.248+0000] {processor.py:161} INFO - Started process (PID=3269) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:38.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:49:38.251+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:49:38.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:41.847+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:49:41.839+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:49:41.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:49:41.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.624 seconds
[2025-05-07T19:50:11.911+0000] {processor.py:161} INFO - Started process (PID=3440) to work on /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:50:11.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/CoronaProj/Spark_script_process.py for tasks to queue
[2025-05-07T19:50:11.913+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:50:11.913+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:50:15.620+0000] {logging_mixin.py:188} INFO - [2025-05-07T19:50:15.612+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/CoronaProj/Spark_script_process.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/CoronaProj/Spark_script_process.py", line 27, in <module>
    df = spark.read.option("multiline", "true").json("data.json")
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py", line 425, in json
    return self._df(self._jreader.json(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py", line 185, in deco
    raise converted from None
pyspark.errors.exceptions.captured.AnalysisException: [PATH_NOT_FOUND] Path does not exist: file:/opt/airflow/data.json.
[2025-05-07T19:50:15.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/CoronaProj/Spark_script_process.py
[2025-05-07T19:50:15.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/CoronaProj/Spark_script_process.py took 3.735 seconds
